# ğŸª¨ğŸ“„âœ‚ï¸ Rockâ€“Paperâ€“Scissors Image Classification (Dicoding Project â€“ 2022)

An image classification project that recognizes **hand gestures (Rock, Paper, Scissors)** using a **Convolutional Neural Network (CNN)**.  
Built during the **Dicoding Machine Learning Academy**, this project demonstrates how computer vision can learn visual patterns through deep learning.

[![Google Colab](https://img.shields.io/badge/Open%20in-Colab-yellow?logo=googlecolab&logoColor=white)](https://colab.research.google.com/drive/1ILXA044PprIbma1NKTVG1NQa8f7lSW8P)

---

## ğŸ¯ Project Overview

This project uses a **CNN model** to automatically classify images of human hands into three categories:
- ğŸª¨ **Rock**
- ğŸ“„ **Paper**
- âœ‚ï¸ **Scissors**

The dataset was provided by Dicoding and processed using **Google Colab**.  
Through **image augmentation** and multi-layer convolution, the model achieved **~95% accuracy** in recognizing hand gestures.

---

## ğŸŒŸ Key Highlights

- Built and trained in **Google Colab** for full cloud reproducibility.  
- Designed a **5-layer CNN** to extract features and classify gestures.  
- Achieved **high accuracy** on validation data within 12 epochs.  
- Integrated **real-time testing** with uploaded images.  
- Demonstrates how deep learning can recognize visual patterns effectively.

---

## ğŸ“Š Example Visualizations

| CNN Layer Architecture | Training Process Output | Prediction Result |
|:--:|:--:|:--:|
| <img src="https://github.com/rizalarb/Rock-Paper-Scissors-Image-Classification/blob/master/CNN%20Layers.png" width="260"/> | <img src="https://github.com/rizalarb/Rock-Paper-Scissors-Image-Classification/blob/master/Training%20Model%20Output.png" width="260"/> | <img src="https://github.com/rizalarb/Rock-Paper-Scissors-Image-Classification/blob/master/Output%20Prediction%20Tes.png" width="260"/> |

---

## ğŸ§° Tools & Frameworks

`Python` â€¢ `TensorFlow / Keras` â€¢ `NumPy` â€¢ `Matplotlib` â€¢ `Google Colab`

---


**Institution:** Dicoding Academy  
**Year:** 2022
